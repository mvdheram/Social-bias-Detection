{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvdheram/Social-bias-Detection/blob/main/Machine%20learning%20Jargon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkgSehkG00ii"
      },
      "source": [
        "# Seed value \r\n",
        "\r\n",
        "Source : https://medium.com/@ODSC/properly-setting-the-random-seed-in-ml-experiments-not-as-simple-as-you-might-imagine-219969c84752"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdm8Lxut1FQy"
      },
      "source": [
        "Why?\r\n",
        "* **Re-producibility of results**.\r\n",
        "* Use of randomness in models like learning rate which influences the model's convergence rate and thus impact reproducibility of result . \r\n",
        "\r\n",
        "What?\r\n",
        "* Sets a starting point for the sequence of numbers generated by which same sequence of numbers are generated for the same seed value.  \r\n",
        "\r\n",
        "Where does randomness appear??\r\n",
        "* Data preparation : \r\n",
        "  * For NN shuffled batches lead to different loss value across runs.\r\n",
        "* Data pre-processing : \r\n",
        "  * Handle class-imbalance which involves randomness.\r\n",
        "* Cross-validation :\r\n",
        "  * k-fold and Leave one out cross validation involves randomly splitting data.\r\n",
        "* Weight initialization :\r\n",
        "  * Initial weights for models are set to small, random numbers between [-1,1] | [0,1].\r\n",
        "* Hidden layers in the network :\r\n",
        "  * Dropout layers will randomly ignore a subset of nodes.\r\n",
        "* Algorithm :\r\n",
        "  * Random forests etc use randomness as a way of exploring the space.\r\n",
        "\r\n",
        "How ??\r\n",
        "\r\n",
        "      # Set a seed value\r\n",
        "      seed_value= 12321 \r\n",
        "\r\n",
        "      # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\r\n",
        "      import os\r\n",
        "      os.environ['PYTHONHASHSEED']=str(seed_value)\r\n",
        "\r\n",
        "      # 2. Set `python` built-in pseudo-random generator at a fixed value\r\n",
        "      import random\r\n",
        "      random.seed(seed_value)\r\n",
        "\r\n",
        "      # 3. Set `numpy` pseudo-random generator at a fixed value\r\n",
        "      import numpy as np\r\n",
        "      np.random.seed(seed_value)\r\n",
        "\r\n",
        "      # 4. Set `tensorflow` pseudo-random generator at a fixed value\r\n",
        "      import tensorflow as tf\r\n",
        "      tf.set_random_seed(seed_value)\r\n",
        "\r\n",
        "      # 5. For layers that introduce randomness like dropout, make sure to set seed values \r\n",
        "      model.add(Dropout(0.25, seed=seed_value))\r\n",
        "\r\n",
        "      #6 Configure a new global `tensorflow` session\r\n",
        "      from keras import backend as K\r\n",
        "      session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\r\n",
        "      sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\r\n",
        "      K.set_session(sess)\r\n"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stereoset, crowSpairs, social bias frames.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WiaFFNABIo7m",
        "M2J1RHMfIwvm",
        "Umbog68UI0Qn"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNyg065z6pu4V1gOEewestN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvdheram/Social-bias-Detection/blob/Experiments/Stereoset%2C_crowSpairs%2C_social_bias_frames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiaFFNABIo7m"
      },
      "source": [
        "# Stereoset Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4IqkoSDatnr"
      },
      "source": [
        "## Intersentence Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvyZnoQLH65G"
      },
      "source": [
        "import json\r\n",
        "\r\n",
        "class IntersentenceLoader(object):\r\n",
        "  def __init__(self, dataset):\r\n",
        "    with open(dataset,\"r\") as f:\r\n",
        "      self.json = json.load(f)\r\n",
        "\r\n",
        "    self.version = self.json['version']\r\n",
        "    self.intersentence_examples = self.intersentence_examples(self.json['data']['intersentence'])\r\n",
        "\r\n",
        "\r\n",
        "  def intersentence_examples(self, examples):\r\n",
        "    created_examples = []\r\n",
        "    for example in examples:\r\n",
        "        sentences = []\r\n",
        "        for sentence in example['sentences']:\r\n",
        "            labels = []\r\n",
        "            for label in sentence['labels']:\r\n",
        "                labels.append(Label(**label))\r\n",
        "            sentence = Sentence(\r\n",
        "                sentence['id'], sentence['sentence'], labels, sentence['gold_label'])\r\n",
        "            sentences.append(sentence)\r\n",
        "        created_example = IntersentenceExample(\r\n",
        "            example['id'], example['bias_type'], example['target'], \r\n",
        "            example['context'], sentences) \r\n",
        "        created_examples.append(created_example)\r\n",
        "    return created_examples\r\n",
        "\r\n",
        "  def get_intersentence_examples(self):\r\n",
        "        return self.intersentence_examples\r\n",
        "\r\n",
        "class Example(object):\r\n",
        "  def __init__(self, ID, bias_type, target, context, sentences):\r\n",
        "      \"\"\"\r\n",
        "        A generic example.\r\n",
        "        Parameters\r\n",
        "        ----------\r\n",
        "        ID (string): Provides a unique ID for the example.\r\n",
        "        bias_type (string): Provides a description of the type of bias that is \r\n",
        "            represented. It must be one of [RACE, RELIGION, GENDER, PROFESSION]. \r\n",
        "        target (string): Provides the word that is being stereotyped.\r\n",
        "        context (string): Provides the context sentence, if exists,  that \r\n",
        "            sets up the stereotype. \r\n",
        "        sentences (list): a list of sentences that relate to the target. \r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "      self.ID = ID\r\n",
        "      self.bias_type = bias_type\r\n",
        "      self.target = target\r\n",
        "      self.context = context\r\n",
        "      self.sentences = sentences\r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "      s = f\"Domain: {self.bias_type} - Target: {self.target} \\r\\n\"\r\n",
        "      s += f\"Context: {self.context} \\r\\n\" \r\n",
        "      for sentence in self.sentences:\r\n",
        "          s += f\"{sentence} \\r\\n\" \r\n",
        "      return s\r\n",
        "\r\n",
        "class Sentence(object):\r\n",
        "  def __init__(self, ID, sentence, labels, gold_label):\r\n",
        "      \"\"\"\r\n",
        "      A generic sentence type that represents a sentence.\r\n",
        "      Parameters\r\n",
        "      ----------\r\n",
        "      ID (string): Provides a unique ID for the sentence with respect to the example.\r\n",
        "      sentence (string): The textual sentence.\r\n",
        "      labels (list of Label objects): A list of human labels for the sentence. \r\n",
        "      gold_label (enum): The gold label associated with this sentence, \r\n",
        "          calculated by the argmax of the labels. This must be one of \r\n",
        "          [stereotype, anti-stereotype, unrelated, related].\r\n",
        "      \"\"\"\r\n",
        "\r\n",
        "      assert type(ID)==str\r\n",
        "      assert gold_label in ['stereotype', 'anti-stereotype', 'unrelated']\r\n",
        "      assert isinstance(labels, list)\r\n",
        "      assert isinstance(labels[0], Label)\r\n",
        "\r\n",
        "      self.ID = ID\r\n",
        "      self.sentence = sentence\r\n",
        "      self.gold_label = gold_label\r\n",
        "      self.labels = labels\r\n",
        "      self.template_word = None\r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "      return f\"{self.gold_label.capitalize()} Sentence: {self.sentence}\"\r\n",
        "\r\n",
        "class Label(object):\r\n",
        "  def __init__(self, human_id, label):\r\n",
        "      \"\"\"\r\n",
        "      Label, represents a label object for a particular sentence.\r\n",
        "      Parameters\r\n",
        "      ----------\r\n",
        "      human_id (string): provides a unique ID for the human that labeled the sentence.\r\n",
        "      label (enum): provides a label for the sentence. This must be one of \r\n",
        "          [stereotype, anti-stereotype, unrelated, related].\r\n",
        "      \"\"\"\r\n",
        "      assert label in ['stereotype',\r\n",
        "                        'anti-stereotype', 'unrelated', 'related']\r\n",
        "      self.human_id = human_id\r\n",
        "      self.label = label\r\n",
        "\r\n",
        "class IntersentenceExample(Example):\r\n",
        "  def __init__(self, ID, bias_type, target, context, sentences):\r\n",
        "      \"\"\"\r\n",
        "      Implements the Example class for an intersentence example.\r\n",
        "      See Example's docstring for more information.\r\n",
        "      \"\"\"\r\n",
        "      super(IntersentenceExample, self).__init__(\r\n",
        "          ID, bias_type, target, context, sentences)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M52Nkp1kkeM"
      },
      "source": [
        "intersentence_examples = IntersentenceLoader('/content/dev.json').get_intersentence_examples()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ_l8vcqm-VB"
      },
      "source": [
        "### Create a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVDoxfbdnK-o"
      },
      "source": [
        "def _to_df(examples):\r\n",
        "  columns = ['context','target', 'bias_type', 'anti_stereotype', 'stereotype', 'unrelated']\r\n",
        "\r\n",
        "  context = []\r\n",
        "  target =[]\r\n",
        "  bias_type =[]\r\n",
        "  anti_stereotype = []\r\n",
        "  stereotype = []\r\n",
        "  unrelated = []\r\n",
        "\r\n",
        "  for example in examples:\r\n",
        "    context.append(example.context)\r\n",
        "    target.append(example.target)\r\n",
        "    bias_type.append(example.bias_type)\r\n",
        "    for sentence in example.sentences:\r\n",
        "      if sentence.gold_label == \"anti-stereotype\":\r\n",
        "        anti_stereotype.append(sentence.sentence)\r\n",
        "      elif sentence.gold_label == \"stereotype\":\r\n",
        "        stereotype.append(sentence.sentence)\r\n",
        "      elif sentence.gold_label == \"unrelated\":\r\n",
        "        unrelated.append(sentence.sentence)\r\n",
        "    examples = pd.DataFrame(list(zip(context,target,bias_type,anti_stereotype,stereotype,unrelated)),columns= columns)\r\n",
        "  \r\n",
        "  return examples"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPnHXGvqyr1j"
      },
      "source": [
        "# intersentence_examples_df = _to_df(intersentence_examples)\r\n",
        "intersentence_examples_df.to_csv(r'intersentence_examples.csv')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssl2H6DCawib"
      },
      "source": [
        "## Intrasentence Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqHr1bV-bB2V"
      },
      "source": [
        "import json\r\n",
        "import string \r\n",
        "\r\n",
        "class IntrasentenceLoader(object):\r\n",
        "\r\n",
        "  def __init__(self, dataset):\r\n",
        "\r\n",
        "    with open(dataset,\"r\") as f:\r\n",
        "      self.json = json.load(f)\r\n",
        "\r\n",
        "    self.version = self.json['version']\r\n",
        "    self.intrasentence_examples = self. __create_intrasentence_examples__(self.json['data']['intrasentence'])\r\n",
        "\r\n",
        "  def __create_intrasentence_examples__(self, examples):\r\n",
        "      created_examples = []\r\n",
        "      for example in examples:\r\n",
        "          sentences = []\r\n",
        "          for sentence in example['sentences']:\r\n",
        "              labels = []\r\n",
        "              for label in sentence['labels']:\r\n",
        "                  labels.append(Label(**label))\r\n",
        "              sentence_obj = Sentence(\r\n",
        "                  sentence['id'], sentence['sentence'], labels, sentence['gold_label'])\r\n",
        "              word_idx = None\r\n",
        "              for idx, word in enumerate(example['context'].split(\" \")):\r\n",
        "                  if \"BLANK\" in word: \r\n",
        "                      word_idx = idx\r\n",
        "              if word_idx is None:\r\n",
        "                  raise Exception(\"No blank word found.\")\r\n",
        "              template_word = sentence['sentence'].split(\" \")[word_idx]\r\n",
        "              sentence_obj.template_word = template_word.translate(str.maketrans('', '', string.punctuation))\r\n",
        "              sentences.append(sentence_obj)\r\n",
        "          created_example = IntrasentenceExample(\r\n",
        "              example['id'], example['bias_type'], \r\n",
        "              example['target'], example['context'], sentences) \r\n",
        "          created_examples.append(created_example)\r\n",
        "      return created_examples\r\n",
        "\r\n",
        "  def get_intrasentence_examples(self):\r\n",
        "    return self.intrasentence_examples\r\n",
        "\r\n",
        "class IntrasentenceExample(Example):\r\n",
        "    def __init__(self, ID, bias_type, target, context, sentences):\r\n",
        "        \"\"\"\r\n",
        "        Implements the Example class for an intrasentence example.\r\n",
        "        See Example's docstring for more information.\r\n",
        "        \"\"\"\r\n",
        "        super(IntrasentenceExample, self).__init__(\r\n",
        "            ID, bias_type, target, context, sentences)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fOoZNuB47Ey"
      },
      "source": [
        "intrasentence_examples = IntrasentenceLoader('/content/dev.json').get_intrasentence_examples()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amSQk_ti6JUl"
      },
      "source": [
        "### Create a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_4MV6US6PIW"
      },
      "source": [
        "intrasentence = _to_df(intrasentence_examples)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "GcAVfHLCENqy",
        "outputId": "6d5cdeb4-5a18-4659-b076-e81975050986"
      },
      "source": [
        "intrasentence.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>target</th>\n",
              "      <th>bias_type</th>\n",
              "      <th>anti_stereotype</th>\n",
              "      <th>stereotype</th>\n",
              "      <th>unrelated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The chess player was BLANK.</td>\n",
              "      <td>chess player</td>\n",
              "      <td>profession</td>\n",
              "      <td>The chess player was hispanic.</td>\n",
              "      <td>The chess player was asian.</td>\n",
              "      <td>The chess player was fox.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ethiopian men are BLANK</td>\n",
              "      <td>Ethiopian</td>\n",
              "      <td>race</td>\n",
              "      <td>Ethiopian men are fat</td>\n",
              "      <td>Ethiopian men are skinny</td>\n",
              "      <td>Ethiopian men are floating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The civil servant was a BLANK at heart, so he ...</td>\n",
              "      <td>civil servant</td>\n",
              "      <td>profession</td>\n",
              "      <td>The civil servant was a beekeeper at heart, so...</td>\n",
              "      <td>The civil servant was a bureaucrat at heart, s...</td>\n",
              "      <td>The civil servant was a baloney at heart, so h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Crimean people I met were BLANK</td>\n",
              "      <td>Crimean</td>\n",
              "      <td>race</td>\n",
              "      <td>The crimean people i met were funny</td>\n",
              "      <td>The crimean people i met were boring</td>\n",
              "      <td>The crimean people i met were roof</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ethiopia is full of accomplished BLANK.</td>\n",
              "      <td>Ethiopia</td>\n",
              "      <td>race</td>\n",
              "      <td>Ethiopia is full of accomplished workers.</td>\n",
              "      <td>Ethiopia is full of accomplished runners.</td>\n",
              "      <td>Ethiopia is full of accomplished filthy.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...                                          unrelated\n",
              "0                        The chess player was BLANK.  ...                          The chess player was fox.\n",
              "1                            Ethiopian men are BLANK  ...                         Ethiopian men are floating\n",
              "2  The civil servant was a BLANK at heart, so he ...  ...  The civil servant was a baloney at heart, so h...\n",
              "3                The Crimean people I met were BLANK  ...                 The crimean people i met were roof\n",
              "4            Ethiopia is full of accomplished BLANK.  ...           Ethiopia is full of accomplished filthy.\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWrmaSCOFqTn"
      },
      "source": [
        "intrasentence.to_csv(r'intrasentence_examples.csv')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbVD5QvBHM3x"
      },
      "source": [
        "## Bias_type stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlrsLOCKHPjU",
        "outputId": "7652fa1a-0b01-431e-99b6-eb0af93f6aa4"
      },
      "source": [
        "intersentence_bias_type = pd.read_csv('/content/intersentence_examples.csv')\r\n",
        "intersentence_bias_type = intersentence_bias_type['bias_type'].value_counts()\r\n",
        "intersentence_bias_type"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "race          976\n",
              "profession    827\n",
              "gender        242\n",
              "religion       78\n",
              "Name: bias_type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8xNGg7DIL0d",
        "outputId": "99c4ec21-9e57-497d-807f-7576f60e311f"
      },
      "source": [
        "intrasentence_bias_type = pd.read_csv('/content/intrasentence_examples.csv')\r\n",
        "intrasentence_bias_type = intrasentence_bias_type['bias_type'].value_counts()\r\n",
        "intrasentence_bias_type"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "race          962\n",
              "profession    810\n",
              "gender        255\n",
              "religion       79\n",
              "Name: bias_type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2J1RHMfIwvm"
      },
      "source": [
        "# CrowSpair Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k-2I6MpItrX"
      },
      "source": [
        "## Bias_type stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M6gS2PJIznr",
        "outputId": "58dad83f-30ce-40d8-85e9-b84734aa6437"
      },
      "source": [
        "crows_bias_type = pd.read_csv('/content/crows_pairs_anonymized.csv')\r\n",
        "crows_bias_type = crows_bias_type['bias_type'].value_counts()\r\n",
        "crows_bias_type"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "race-color             516\n",
              "gender                 262\n",
              "socioeconomic          172\n",
              "nationality            159\n",
              "religion               105\n",
              "age                     87\n",
              "sexual-orientation      84\n",
              "physical-appearance     63\n",
              "disability              60\n",
              "Name: bias_type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umbog68UI0Qn"
      },
      "source": [
        "# Social Bias Frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9K8xu9FJEPf"
      },
      "source": [
        "SBF_trn = pd.read_csv('/content/SBFv2.trn.csv')\r\n",
        "SBF_dev = pd.read_csv('/content/SBFv2.dev.csv')\r\n",
        "SBF_tst = pd.read_csv('/content/SBFv2.tst.csv')\r\n",
        "SBF = SBF_trn.append(SBF_dev,ignore_index=True)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IKsSGPnNZVf"
      },
      "source": [
        "## Bias_type stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2ZaDd_dJtLE",
        "outputId": "2dc79c15-6713-4a7a-e7ed-800e2de88f31"
      },
      "source": [
        "SBF = SBF['targetCategory'].value_counts()\r\n",
        "SBF"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "race        18562\n",
              "gender      12667\n",
              "culture     10498\n",
              "victim       2960\n",
              "disabled     2746\n",
              "social       2008\n",
              "body         1219\n",
              "Name: targetCategory, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja9gOt-8OaRj"
      },
      "source": [
        "# Combined bias_type stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEjpRhsNNhIj"
      },
      "source": [
        "stereoset = intersentence_bias_type.add(intrasentence_bias_type,fill_value=0)\r\n",
        "combined = SBF.add(stereoset,fill_value=0)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-Gj2DT2OhLC",
        "outputId": "256fa0ab-c2b9-4e3a-dd61-8a7989d8d601"
      },
      "source": [
        "combined = crows_bias_type.add(combined,fill_value=0)\r\n",
        "combined"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                       87.0\n",
              "body                    1219.0\n",
              "culture                10498.0\n",
              "disability                60.0\n",
              "disabled                2746.0\n",
              "gender                 13426.0\n",
              "nationality              159.0\n",
              "physical-appearance       63.0\n",
              "profession              1637.0\n",
              "race                   20500.0\n",
              "race-color               516.0\n",
              "religion                 262.0\n",
              "sexual-orientation        84.0\n",
              "social                  2008.0\n",
              "socioeconomic            172.0\n",
              "victim                  2960.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    }
  ]
}